# Quotes Scraper

This repository hosts a Python-based web scraping project that extracts quotes and their corresponding authors' detailed information from [Quotes to Scrape](http://quotes.toscrape.com) website. It demonstrates practical web scraping techniques using `BeautifulSoup4` to navigate and parse HTML, extracting meaningful data and saving it in a structured JSON format.
Additionally, it features a MongoDB integration script within the `database` folder, demonstrating a comprehensive data handling pipeline from extraction to storage in a NoSQL database.

## Features

- **Scrape Quotes:** Dynamically navigates through the homepage and subsequent pages to scrape quotes, authors, and associated tags.
- **Author Details:** Collects detailed information about each author, including their full name, birth date, birth location, and a brief description.
- **JSON Output:** Outputs two well-structured JSON files (`quotes.json` and `authors.json`) for easy integration and reuse in various applications.
- **MongoDB Integration:** Includes a script within the `database` folder for uploading the scraped data to MongoDB, demonstrating a seamless workflow from scraping to data persistence.

## Installation and Usage

#### Setting Up the Project

- **Clone the Repository:**
```bash
git clone https://github.com/alex-nuclearboy/goit-python-web-hw9.git
```

- **Navigate to the Project Directory:**
```bash
cd goit-python-web-hw9
```

- **Activate the Poetry environment and install dependencies:**
```bash
poetry shell
poetry install
```
#### Running the Scraper

- **Run the Script:**
    - Unix/Linux/macOS:
    ```bash
    python3 main.py
    ```
    - Windows:
    ```powershell
    py main.py
    ```

After execution, two JSON files will be generated in the project directory:

- `quotes.json`: Contains the scraped quotes.
- `authors.json`: Contains detailed information about the authors.

#### MongoDB Integration

- Navigate to the `database` folder:
```bash
cd database
```

- Run the MongoDB upload script:
    - Unix/Linux/macOS:
    ```bash
    python3 seeds.py
    ```
    - Windows:
    ```powershell
    py seeds.py
    ```

This script reads the contents of `quotes.json` and `authors.json` and upload them to a MongoDB database, organizing them into `quotes` and `authors` collections respectively.

The JSON files generated by this scraper can be seamlessly imported into the [goit-python-web-hw8](https://github.com/alex-nuclearboy/goit-python-web-hw8) project, facilitating data reuse and integration across projects.